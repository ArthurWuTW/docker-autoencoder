{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9f6007-58c0-460d-9ba0-1556c1524afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.is_available()\n",
    "from torchsummary import summary\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e25620e-5134-4914-bd11-bee9a8fe3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms images to a PyTorch Tensor\n",
    "tensor_transform = transforms.ToTensor()\n",
    " \n",
    "# Download the MNIST Dataset\n",
    "dataset = datasets.MNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = tensor_transform)\n",
    " \n",
    "# DataLoader is used to load the dataset \n",
    "# for training\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "indices = [idx for idx, target in enumerate(dataset.targets) if target in labels]\n",
    "loader = torch.utils.data.DataLoader(torch.utils.data.Subset(dataset, indices),\n",
    "                                     batch_size = 32,\n",
    "                                     shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee73ca13-5805-40e9-b2fc-24e6a8726d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795e188a-b123-418c-85be-cba5d56e3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model structure\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        codes = self.encoder(inputs)\n",
    "        return codes\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.decoder(inputs)\n",
    "        return outputs\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = Encoder()\n",
    "        # Decoder\n",
    "        self.decoder = Decoder()    \n",
    "    def forward(self, inputs): # 修改縮排20241226\n",
    "        codes = self.encoder(inputs)\n",
    "        decoded = self.decoder(codes)\n",
    "        return codes, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52656c3d-e341-4724-ae4b-f9ff1abe3a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 256]         200,960\n",
      "              Tanh-2               [-1, 1, 256]               0\n",
      "            Linear-3               [-1, 1, 128]          32,896\n",
      "              Tanh-4               [-1, 1, 128]               0\n",
      "            Linear-5                [-1, 1, 64]           8,256\n",
      "              Tanh-6                [-1, 1, 64]               0\n",
      "            Linear-7                 [-1, 1, 2]             130\n",
      "              Tanh-8                 [-1, 1, 2]               0\n",
      "================================================================\n",
      "Total params: 242,242\n",
      "Trainable params: 242,242\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.92\n",
      "Estimated Total Size (MB): 0.93\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]             192\n",
      "              Tanh-2                [-1, 1, 64]               0\n",
      "            Linear-3               [-1, 1, 128]           8,320\n",
      "              Tanh-4               [-1, 1, 128]               0\n",
      "            Linear-5               [-1, 1, 256]          33,024\n",
      "              Tanh-6               [-1, 1, 256]               0\n",
      "            Linear-7               [-1, 1, 784]         201,488\n",
      "           Sigmoid-8               [-1, 1, 784]               0\n",
      "================================================================\n",
      "Total params: 243,024\n",
      "Trainable params: 243,024\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.93\n",
      "Estimated Total Size (MB): 0.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "use_cuda = 1\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() & use_cuda) else \"cpu\")\n",
    "\n",
    "model_encoder = Encoder().to(device)\n",
    "model_decoder = Decoder().to(device)\n",
    "\n",
    "summary(model_encoder, (1, 784))\n",
    "summary(model_decoder, (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d58a07-33b6-4ecc-8ba1-76fe9e9f0181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] Loss: 0.0016484769294038415\n"
     ]
    }
   ],
   "source": [
    "optimizer_En = torch.optim.Adam(model_encoder.parameters(), lr=lr)\n",
    "optimizer_De = torch.optim.Adam(model_decoder.parameters(), lr=lr)\n",
    "loss_function = nn.MSELoss().to(device)# Train\n",
    "model_encoder.train()\n",
    "model_decoder.train()\n",
    "log_loss=[]\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for data, _ in loader:\n",
    "        inputs = data.view(-1, 784).to(device) \n",
    "        \n",
    "        model_encoder.zero_grad()\n",
    "        model_decoder.zero_grad()\n",
    "        \n",
    "        codes = model_encoder(inputs)\n",
    "        decoded = model_decoder(codes)\n",
    "        loss = loss_function(decoded, inputs)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer_En.step()\n",
    "        optimizer_De.step()\n",
    "        \n",
    "        total_loss+=loss\n",
    "        log_loss.append(loss)\n",
    "    total_loss /= len(loader.dataset)\n",
    "    \n",
    "    if epoch % 5 ==0:\n",
    "        print('[{}/{}] Loss:'.format(epoch+1, epochs), total_loss.item())\n",
    "print('[{}/{}] Loss:'.format(epoch+1, epochs), total_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51295a-f08f-4a51-b540-765bef08ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_encoder, 'mode_AutoEncoder_MNIST_Encoder3.pth')\n",
    "torch.save(model_decoder, 'mode_AutoEncoder_MNIST_Decoder3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf729d-372f-439e-ae8d-fdedbc48bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform= transforms.ToTensor())\n",
    "\n",
    "# Exclude Label 5 Test \n",
    "labels_t1 = [1, 2, 3, 4, 5]\n",
    "indices_t1 = [idx for idx, target in enumerate(test_dataset.targets) if target in labels_t1]\n",
    "loader_t1 = torch.utils.data.DataLoader(torch.utils.data.Subset(test_dataset, indices_t1),\n",
    "                                     batch_size = 1,\n",
    "                                     shuffle = True)\n",
    "\n",
    "# Label 5 \n",
    "labels_t2 = [6, 7, 8, 9, 0]\n",
    "indices_t2 = [idx for idx, target in enumerate(test_dataset.targets) if target in labels_t2]\n",
    "loader_t2 = torch.utils.data.DataLoader(torch.utils.data.Subset(test_dataset, indices_t2),\n",
    "                                     batch_size = 1,\n",
    "                                     shuffle = True)\n",
    "\n",
    "print(len(loader_t1))\n",
    "print(len(loader_t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1dcb4-4bbe-4e9c-85d6-7267253f22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(sqrtn, sqrtn, index+1)\n",
    "        plt.imshow(image.reshape(28, 28))\n",
    "        plt.axis('off')# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc266f-69bc-4783-8551-a8dec0e405d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "loss_exclude_dist_arr = []\n",
    "model_encoder.eval()\n",
    "model_decoder.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(loader_t1):\n",
    "        inputs = data.view(-1, 28*28).to(device)\n",
    "        # Forward\n",
    "        model_encoder.zero_grad()\n",
    "        model_decoder.zero_grad()\n",
    "        \n",
    "        codes = model_encoder(inputs)\n",
    "        decoded = model_decoder(codes)\n",
    "\n",
    "        if i<3:\n",
    "            show_images(inputs.detach().cpu())\n",
    "            plt.show()# Forward\n",
    "    \n",
    "            show_images(decoded.detach().cpu())\n",
    "            plt.show()# Forward\n",
    "            \n",
    "            print(loss.item()) \n",
    "        \n",
    "        \n",
    "        loss = criterion(inputs.to(device), decoded)\n",
    "        loss_exclude_dist_arr.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb52334-39fe-4984-9e7a-733613791a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "loss_anomaly_dist_arr = []\n",
    "model_encoder.eval()\n",
    "model_decoder.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(loader_t2):\n",
    "        inputs = data.view(-1, 28*28).to(device)\n",
    "        # Forward\n",
    "        model_encoder.zero_grad()\n",
    "        model_decoder.zero_grad()\n",
    "        \n",
    "        codes = model_encoder(inputs)\n",
    "        decoded = model_decoder(codes)\n",
    "\n",
    "        if i<3:\n",
    "            show_images(inputs.detach().cpu())\n",
    "            plt.show()# Forward\n",
    "    \n",
    "            show_images(decoded.detach().cpu())\n",
    "            plt.show()# Forward\n",
    "            \n",
    "            print(loss.item())        \n",
    "        \n",
    "        loss = criterion(inputs.to(device), decoded)\n",
    "        loss_anomaly_dist_arr.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938b75c-d671-444d-ab03-32b405936d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loss_exclude_dist_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c7c99-88ab-4ac6-8765-339782309875",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loss_anomaly_dist_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd2e57-7a0b-43a9-9387-4272b3e2d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "all_test_loss = loss_exclude_dist_arr + loss_anomaly_dist_arr\n",
    "len(all_test_loss)\n",
    "threshold = 0.04\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Loss Distribution')\n",
    "sns.histplot(all_test_loss, bins=100,kde=True, color='blue')\n",
    "plt.axvline(threshold, 0.0, 10, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169587c6-6367-46b4-ac62-ec204b52b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "# Anomaly detection: true positive: it is anomaly and it is detected as anomaly\n",
    "for i, v in enumerate(loss_anomaly_dist_arr):\n",
    "    if v >= threshold:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n",
    "for i, v in enumerate(loss_exclude_dist_arr):\n",
    "    if v < threshold:\n",
    "        tn += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "print('[TP] {}\\t[FP] {}\\t'.format(tp, fp))\n",
    "print('[TN] {}\\t[FN] {}'.format(tn, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde60357-7807-4b5e-bd3d-8101d1e1bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = [[tn,fp],[fn,tp]]\n",
    "plt.figure()\n",
    "s = sns.heatmap(conf,annot=True,annot_kws={\"size\": 16},fmt='g')\n",
    "s.set(xlabel='Predicted', ylabel='Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7e973-e965-4282-a9cc-a1ad5bdefdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "print('precision {}'.format(precision))\n",
    "print('recall {}'.format(recall))\n",
    "print('f1 Score {}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac602dbe-3546-4392-b9ff-ffcd93c3e0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd716b5-b490-43df-a8b4-85d93a17016e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
